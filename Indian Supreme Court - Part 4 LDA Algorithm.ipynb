{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484625</td>\n",
       "      <td>['littttttj', 'maintainedbeforethe', 'motor', ...</td>\n",
       "      <td>littttttj maintainedbeforethe motor accident t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60864</td>\n",
       "      <td>['littttttj', 'sethijthe', 'complaint', 'thene...</td>\n",
       "      <td>littttttj sethijthe complaint thenegotiable in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373794</td>\n",
       "      <td>['complaint', 'forwardedby', 'magistrate', 'po...</td>\n",
       "      <td>complaint forwardedby magistrate police regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55804</td>\n",
       "      <td>['littttttj', 'sye', 'quadri', 'jthis', 'benga...</td>\n",
       "      <td>littttttj sye quadri jthis bengal electricity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301256</td>\n",
       "      <td>['litttttttjsethijdelay', 'condonedleave', 'gr...</td>\n",
       "      <td>litttttttjsethijdelay condonedleave grantedthe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document Id                                             Tokens  \\\n",
       "0       484625  ['littttttj', 'maintainedbeforethe', 'motor', ...   \n",
       "1        60864  ['littttttj', 'sethijthe', 'complaint', 'thene...   \n",
       "2      1373794  ['complaint', 'forwardedby', 'magistrate', 'po...   \n",
       "3        55804  ['littttttj', 'sye', 'quadri', 'jthis', 'benga...   \n",
       "4       301256  ['litttttttjsethijdelay', 'condonedleave', 'gr...   \n",
       "\n",
       "                                              Corpus  \n",
       "0  littttttj maintainedbeforethe motor accident t...  \n",
       "1  littttttj sethijthe complaint thenegotiable in...  \n",
       "2  complaint forwardedby magistrate police regist...  \n",
       "3  littttttj sye quadri jthis bengal electricity ...  \n",
       "4  litttttttjsethijdelay condonedleave grantedthe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_india_1999 = pd.read_csv('Supreme_Court_cases_India_tokens_above_1999_final.csv')\n",
    "sc_india_1999.drop(sc_india_1999.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "sc_india_1999.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20269, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_india_1999.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20269 entries, 0 to 20268\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Document Id  20269 non-null  int64 \n",
      " 1   Tokens       20269 non-null  object\n",
      " 2   Corpus       20234 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 475.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sc_india_1999.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_india_1999.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>accompany</th>\n",
       "      <th>accord</th>\n",
       "      <th>accordance</th>\n",
       "      <th>...</th>\n",
       "      <th>wide</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>withthe</th>\n",
       "      <th>witness</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>writ</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.017726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014647</td>\n",
       "      <td>0.022535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019879</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072160</td>\n",
       "      <td>0.174550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026454</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167605</td>\n",
       "      <td>0.013644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20234 rows Ã— 1087 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able   absence  absolute  absolutely  abuse    accept  acceptance  \\\n",
       "0       0.0  0.000000       0.0    0.000000    0.0  0.000000    0.000000   \n",
       "1       0.0  0.014353       0.0    0.000000    0.0  0.011007    0.000000   \n",
       "2       0.0  0.000000       0.0    0.000000    0.0  0.000000    0.000000   \n",
       "3       0.0  0.006481       0.0    0.000000    0.0  0.019879    0.030232   \n",
       "4       0.0  0.000000       0.0    0.000000    0.0  0.000000    0.000000   \n",
       "...     ...       ...       ...         ...    ...       ...         ...   \n",
       "20229   0.0  0.000000       0.0    0.000000    0.0  0.000000    0.000000   \n",
       "20230   0.0  0.013731       0.0    0.000000    0.0  0.000000    0.000000   \n",
       "20231   0.0  0.000000       0.0    0.034837    0.0  0.000000    0.000000   \n",
       "20232   0.0  0.000000       0.0    0.000000    0.0  0.013335    0.000000   \n",
       "20233   0.0  0.000000       0.0    0.000000    0.0  0.000000    0.000000   \n",
       "\n",
       "       accompany    accord  accordance  ...      wide  withdraw   withthe  \\\n",
       "0            0.0  0.014558    0.017726  ...  0.000000  0.000000  0.053341   \n",
       "1            0.0  0.022146    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2            0.0  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3            0.0  0.005000    0.024350  ...  0.000000  0.008915  0.000000   \n",
       "4            0.0  0.000000    0.000000  ...  0.112105  0.000000  0.000000   \n",
       "...          ...       ...         ...  ...       ...       ...       ...   \n",
       "20229        0.0  0.022689    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "20230        0.0  0.010593    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "20231        0.0  0.000000    0.011240  ...  0.000000  0.000000  0.000000   \n",
       "20232        0.0  0.000000    0.000000  ...  0.000000  0.047842  0.000000   \n",
       "20233        0.0  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "        witness      word      work  writ     write   writing  wrong  \n",
       "0      0.000000  0.000000  0.000000   0.0  0.000000  0.000000    0.0  \n",
       "1      0.000000  0.026636  0.000000   0.0  0.014647  0.022535    0.0  \n",
       "2      0.000000  0.015058  0.015072   0.0  0.000000  0.000000    0.0  \n",
       "3      0.000000  0.072160  0.174550   0.0  0.026454  0.040698    0.0  \n",
       "4      0.000000  0.000000  0.000000   0.0  0.000000  0.000000    0.0  \n",
       "...         ...       ...       ...   ...       ...       ...    ...  \n",
       "20229  0.167605  0.013644  0.000000   0.0  0.015006  0.000000    0.0  \n",
       "20230  0.071136  0.000000  0.000000   0.0  0.014012  0.000000    0.0  \n",
       "20231  0.000000  0.000000  0.000000   0.0  0.000000  0.000000    0.0  \n",
       "20232  0.000000  0.048403  0.000000   0.0  0.000000  0.000000    0.0  \n",
       "20233  0.000000  0.000000  0.000000   0.0  0.000000  0.000000    0.0  \n",
       "\n",
       "[20234 rows x 1087 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_vectorizer\n",
    "max_df = 9.09\n",
    "min_df = 0.07\n",
    "features = 3000\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = max_df, min_df = min_df,  max_features = features)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sc_india_1999['Corpus'])\n",
    "\n",
    "sc_india_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "sc_india_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.63921478, 27.49120153, 23.97138786, ..., 69.57678176,\n",
       "        11.52696366, 19.43006645],\n",
       "       [ 0.10004098,  1.36254747,  0.10025175, ...,  0.92202783,\n",
       "         0.10001008,  0.10028527],\n",
       "       [ 0.10001069,  0.10000458,  0.10000748, ...,  0.10000825,\n",
       "         0.10000611,  0.10000861],\n",
       "       ...,\n",
       "       [ 0.10000118,  0.10000135,  0.10000093, ...,  0.10000092,\n",
       "         0.10000054,  0.10000095],\n",
       "       [ 4.22258286,  8.4811536 ,  2.95180471, ...,  9.28501623,\n",
       "         3.49779024,  4.50537858],\n",
       "       [ 0.10000116,  0.10000126,  0.10000083, ...,  0.10000085,\n",
       "         0.10000109,  0.10000075]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(sc_india_matrix)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_topics(corpus):\n",
    "    max_df = 9.09\n",
    "    min_df = 0.07\n",
    "    features = 3000\n",
    "    top_words = 20\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df = max_df, min_df = min_df, max_features = features)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "    sc_india_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "    \n",
    "    lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(sc_india_matrix)\n",
    "    tfidf_features = tfidf_vectorizer.get_feature_names()\n",
    "    \n",
    "    topicdict = {}\n",
    "    for idx, topic in enumerate(lda.components_):\n",
    "        topicdict[idx]=\" \".join([tfidf_features[i] for i in topic.argsort()[:-top_words -1:-1]])\n",
    "    return tfidf_matrix, lda, topicdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix, lda_test, ldaword = lda_topics(sc_india_1999['Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "land property respondent appellant plaintiff order high decree date possession agreement party sale acquisition rent deed award application judgment learn\n",
      "Topic #1:\n",
      "order high petition learn appellant counsel pass hear respondent dispose date party writ civil application matter impugned direct accordingly disposed\n",
      "Topic #2:\n",
      "council bar advocate committee complainant guilty punishment complaint practice cease strike remove withthe substitute allegation large appellant association properly chapter\n",
      "Topic #3:\n",
      "compensation vehicle rs award tribunal commission loss national appellant company deceased forum income pay policy high owner respondent liability injury\n",
      "Topic #4:\n",
      "service respondent order high appellant date writ post petition employee appointment candidate issue authority committee tribunal hold article learn shall\n",
      "Topic #5:\n",
      "accuse offence criminal appellant sentence bail high order magistrate complaint trial code police complainant respondent learn investigation ipc imprisonment date\n",
      "Topic #6:\n",
      "pw accuse deceased evidence appellant witness prosecution injury ipc trial sentence offence death police high house statement incident conviction record\n",
      "Topic #7:\n",
      "order respondent entry excise officer high rigorous award charge grave time tribunal good sentence conclusion acquit statement impose evidence service\n",
      "Topic #8:\n",
      "tax excise good tribunal sale manufacture duty income commissioner order central product notification assessment appellant provision company use value custom\n",
      "Topic #9:\n",
      "market fee nos order appellant tax contract committee high service good rigorous payable fund value employee land grave pay demand\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "#print topic words    \n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(lda_test, tfidf_feature_names,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
